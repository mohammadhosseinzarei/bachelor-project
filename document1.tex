\documentclass[12pt]{article}
\usepackage{xepersian}
\settextfont{B Nazanin}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\setlatintextfont{Times New Roman}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage[a4paper, margin=2cm]{geometry} 
\usepackage{lipsum}
\usepackage{float}
\begin{document}
\begin{titlepage}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.5\textwidth]{vru/vru.png}
		\label{fig:my_label}
	\end{figure}
	\vspace{1cm}
	\centering
	{\huge نام  پروژه : کاربرد آمار در یادگیری ماشین}\\[0.5cm]
	{\large نام و نام خانوادگی دانشجو : محمد حسین زارعی}\\
	\vspace{0.5cm}
	{\large استاد راهنما: دکتر عباس مهدوی}\\[2cm]
	{\large پاییز ۱۴۰۴}
\end{titlepage}
{
	\newgeometry{top=2cm, bottom=1cm, left=1cm, right=1cm} % بدون حاشیه
	\tableofcontents
	\restoregeometry % بازگرداندن تنظیمات قبلی
	\newpage
} 
\section{مقدمه}
یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به ماشین‌ها امکان می‌دهد از داده‌ها یاد بگیرند و رفتارهای هوشمندانه‌ای مشابه انسان‌ها بروز دهند، بدون اینکه به‌صورت صریح برنامه‌ریزی شوند. این فناوری به ماشین‌ها اجازه می‌دهد با استفاده از الگوریتم‌های یادگیری، الگوها و روابط موجود در داده‌ها را شناسایی کرده و بر اساس آن‌ها تصمیم‌گیری کنند یا به محیط اطراف خود تأثیر بگذارند.\\
در یک نگاه ساده، یادگیری ماشین می‌تواند به دو صورت عمل کند: در روش سنتی، برنامه‌نویسان با استفاده از عملیات منطقی و ریاضی، برنامه‌ای مشخص را برای ماشین طراحی می‌کنند. برای مثال، در مدیریت موجودی کارخانه، برنامه‌نویس با دریافت فرمول مقدار اقتصادی سفارش، برنامه نویسی می کند. که با تحلیل داده‌های موجودی و پارامترهای محیطی، مقدار بهینه سفارش را محاسبه و اعلام می‌کند. اما در رویکرد مدرن یادگیری ماشین، به جای ارائه برنامه‌های از پیش تعیین‌شده، ماشین با قرار گرفتن در معرض داده‌ها و بهره‌گیری از الگوریتم‌های یادگیری، به‌تدریج مدل‌های مورد نیاز خود را شکل می‌دهد. این فرایند مشابه یادگیری انسان‌ها، مانند کودکی است که به‌تدریج زبان را می‌آموزد و توانایی صحبت کردن را کسب می‌کند.\\
یادگیری ماشین
 (\lr{Machine Learning}) 
در سال‌های اخیر پیشرفت‌های چشمگیری داشته و در حوزه‌های مختلف کاربردهای پیشرفته‌ای پیدا کرده است. در ادامه، به برخی از مثال‌های پیشرفته و نوآورانه یادگیری ماشین اشاره می‌کنم که نشان‌دهنده قدرت و تنوع این فناوری هستند:
\begin{enumerate}

\item تشخیص و درمان پزشکی پیشرفته:  
- تشخیص سرطان با دقت بالا: الگوریتم‌های یادگیری عمیق 
(\lr{Deep Learning})
 مانند شبکه‌های کانولوشنی 
 (\lr{CNN}) 
 برای تحلیل تصاویر پزشکی
  (\lr{MRI}، \lr{CT}، و ماموگرافی) 
 استفاده می‌شوند. برای مثال، مدل‌های
  \lr{AI} مانند
   \lr{Google Health’s DeepMind} 
   در تشخیص سرطان پستان از تصاویر ماموگرافی،
    گاهی دقت بیشتری نسبت به رادیولوژیست‌های انسانی دارند.
- **پیش‌بینی بیماری‌های ژنتیکی**: ابزارهایی مثل 
\lr{AlphaFold  DeepMind}
 ساختار پروتئین‌ها را با دقت بی‌سابقه‌ای پیش‌بینی می‌کنند که در توسعه داروهای جدید برای بیماری‌های پیچیده مانند آلزایمر یا سرطان نقش مهمی دارند.

\item  پردازش زبان طبیعی \lr{(NLP)}:  
مدل‌های زبانی پیشرفته: مدل‌هایی مانند
\lr{GPT-4} 
 یا
\lr{LLaMA}
   با تحلیل حجم عظیمی از داده‌های متنی، توانایی تولید متن‌های شبیه انسان، پاسخ به سؤالات پیچیده، ترجمه زبان‌ها، و حتی نوشتن کد را دارند. این مدل‌ها در چت‌بات‌ها، دستیارهای مجازی، و تحلیل احساسات 
\lr{(Sentiment Analysis)} 
  کاربرد دارند.
- ترجمه بلادرنگ: سیستم‌هایی مانند
\lr{Google Translate}
  با استفاده از یادگیری ماشین، ترجمه‌های صوتی و متنی را به‌صورت بلادرنگ با دقت بالا انجام می‌دهند.

\item بینایی کامپیوتری:  
-تشخیص اشیا و چهره: الگوریتم‌های یادگیری عمیق در سیستم‌های امنیتی برای شناسایی چهره‌ها یا تشخیص اشیا در تصاویر و ویدئوها استفاده می‌شوند. مثلاً، سیستم‌های نظارت شهری از این فناوری برای شناسایی رفتارهای مشکوک بهره می‌برند.
- خودروهای خودران: شرکت‌هایی مثل 
\lr{Tesla} و \lr{Waymo}
از یادگیری ماشین برای پردازش داده‌های حسگرها 
(\lr{LiDAR}، دوربین‌ها) 
استفاده می‌کنند تا خودروها بتوانند موانع، علائم راهنمایی، و مسیرها را شناسایی کرده و رانندگی ایمن انجام دهند.

\item یادگیری تقویتی در رباتیک:  
- ربات‌های خودآموز: الگوریتم‌های یادگیری تقویتی
\lr{(Reinforcement Learning)}
  به ربات‌ها امکان می‌دهند تا از طریق آزمون‌وخطا وظایف پیچیده‌ای مانند راه رفتن، گرفتن اشیا، یا حتی انجام جراحی را یاد بگیرند. برای مثال، ربات‌های
\lr{Boston Dynamics} 
 از این فناوری برای حرکات پویا و تعادل استفاده می‌کنند.
- **بازی‌های استراتژیک**: مدل‌هایی مثل
\lr{AlphaGo} 
 از
\lr{DeepMind4}
 با استفاده از یادگیری تقویتی، استراتژی‌های پیچیده‌ای را در بازی‌های تخته‌ای مانند
\lr{Go}
   توسعه داده‌اند که حتی قهرمانان انسانی را شکست داده‌اند.

\item توصیه‌گرهای هوشمند:  
- سیستم‌های پیشنهاددهنده: پلتفرم‌هایی مانند
\lr{Netflix}، \lr{Spotify}، و \lr{Amazon} 
 از الگوریتم‌های یادگیری ماشین 
 (مانند
 \lr{Collaborative Filtering} 
  و یادگیری عمیق) 
 برای تحلیل رفتار کاربران و پیشنهاد محتوا یا محصولات شخصی‌سازی‌شده استفاده می‌کنند.
- تبلیغات هدفمند: شرکت‌های تبلیغاتی از یادگیری ماشین برای تحلیل داده‌های کاربران و ارائه تبلیغات متناسب با علایق آن‌ها بهره می‌برند.

\item پیش‌بینی و تحلیل داده‌های کلان:  
- پیش‌بینی بازارهای مالی: الگوریتم‌های یادگیری ماشین برای تحلیل روندهای بازار، پیش‌بینی قیمت سهام، و مدیریت ریسک در مؤسسات مالی استفاده می‌شوند.
- **مدیریت زنجیره تأمین**: شرکت‌هایی مانند
\lr{Walmart} 
از یادگیری ماشین برای بهینه‌سازی موجودی، پیش‌بینی تقاضا، و مدیریت لجستیک استفاده می‌کنند.

\item کشف دارو و زیست‌فناوری:  
- طراحی مولکول‌های جدید: 
\lr{AI}
 با شبیه‌سازی تعاملات شیمیایی، ترکیبات دارویی جدید را پیشنهاد می‌دهد. برای مثال، شرکت 
\lr{Insilico Medicine}
  از یادگیری ماشین برای کشف داروهای جدید در زمان کوتاه‌تر استفاده کرده است.
- تحلیل داده‌های ژنومی: الگوریتم‌ها برای شناسایی جهش‌های ژنتیکی و پیش‌بینی پاسخ بیماران به درمان‌های خاص استفاده می‌شوند.

\item کشاورزی هوشمند:  
- کشاورزی دقیق: یادگیری ماشین با تحلیل داده‌های حسگرها، تصاویر ماهواره‌ای، و داده‌های آب‌وهوایی، به کشاورزان کمک می‌کند تا زمان مناسب کاشت، آبیاری، و برداشت را تعیین کنند. مثلاً، سیستم‌های 
\lr{AI}
 می‌توانند آفات یا بیماری‌های گیاهی را زودهنگام تشخیص دهند.
- اتوماسیون مزارع: ربات‌های مجهز به 
\lr{AI} 
برای کاشت، برداشت، و حتی جمع‌آوری داده‌های خاک استفاده می‌شوند.

\item امنیت سایبری:  
- تشخیص تهدیدات: الگوریتم‌های یادگیری ماشین برای شناسایی حملات سایبری، بدافزارها، و رفتارهای غیرعادی در شبکه‌ها استفاده می‌شوند. مثلاً، سیستم‌های تشخیص نفوذ 
\lr{(IDS)} از \lr{AI} 
برای تحلیل ترافیک شبکه بهره می‌برند.
- احراز هویت بیومتریک:
\lr{AI}
  در سیستم‌های تشخیص صدا یا اثر انگشت برای افزایش امنیت کاربرد دارد.

\item هنر و خلاقیت:  
- تولید محتوا: ابزارهایی مانند
\lr{DALL-E}
 یا 
\lr{MidJourney} 
 با استفاده از یادگیری عمیق، تصاویر، موسیقی، یا حتی داستان‌هایی خلاقانه تولید می‌کنند که مشابه آثار انسانی هستند.
- تحلیل سبک‌های هنری: \lr{AI} می‌تواند آثار هنری را تحلیل کرده و سبک‌های جدید خلق کند یا حتی در مرمت آثار باستانی کمک کند.

ویژگی‌های پیشرفته این کاربردها:
- یادگیری عمیق: استفاده از شبکه‌های عصبی عمیق با لایه‌های متعدد برای پردازش داده‌های پیچیده.
- تحلیل داده‌های کلان: توانایی پردازش حجم عظیمی از داده‌ها در زمان کوتاه.
- تطبیق‌پذیری: قابلیت یادگیری و بهبود مستمر با داده‌های جدید.
-تعامل چندحوزه‌ای: ترکیب یادگیری ماشین با حسگرها، رباتیک، و اینترنت اشیا
(\lr{IoT}).

این مثال‌ها تنها بخشی از پتانسیل یادگیری ماشین را نشان می‌دهند. با پیشرفت الگوریتم‌ها و افزایش قدرت محاسباتی، انتظار می‌رود که کاربردهای پیشرفته‌تری در آینده ظهور کنند که زندگی بشر را بیش از پیش متحول کنند.
\end{enumerate}


\section{انواع یادگیری}

 در یادگیری ماشین با دونوع یادگیری مواجه می شویم، که یک نوع آن یادگیری نظارت‌شده 
\lr{(Supervised Learning)}
 یکی از شاخه‌های اصلی یادگیری ماشین است که در آن مدل با استفاده از داده‌های برچسب‌دار آموزش می‌بیند. در این روش، داده‌های ورودی (ویژگی‌ها) همراه با خروجی‌های متناظر (برچسب‌ها) به مدل ارائه می‌شوند تا مدل بتواند رابطه بین ورودی‌ها و خروجی‌ها را یاد بگیرد و از آن برای پیش‌بینی خروجی‌های جدید استفاده کند.
 مفاهیم اصلی:
 \begin{itemize}[label={\color{black}$\bullet$}]
 \item داده‌های برچسب‌دا: داده‌های آموزشی شامل دو بخش هستند:
 
ویژگی‌ها، برچسب
\item \lr{(Features)}: متغیرهای ورودی که مدل از آن‌ها برای یادگیری استفاده می‌کند (مثل قد، وزن، یا دما).

\item \lr{ برچسب (Labels)}
: خروجی‌های مورد انتظار که مدل باید پیش‌بینی کند (مثل "مثبت" یا "منفی" در طبقه‌بندی، یا یک عدد در رگرسیون).
انواع مسائل در یادگیری نظارت‌شد:
\item رگرسیون
\lr{ (Regression)}
: پیش‌بینی یک مقدار پیوسته، مثل پیش‌بینی قیمت خانه یا دمای هوا.
\item طبقه‌بندی 
\lr{(Classification)}
: پیش‌بینی یک دسته یا کلاس، مثل تشخیص ایمیل به‌عنوان "هرزنامه" یا "غیرهرزنامه".
مراحل یادگیری نظارت‌شده:
\item جمع‌آوری داده: تهیه مجموعه داده‌ای با ویژگی‌ها و برچسب‌های دقیق.
\item آموزش مدل: استفاده از الگوریتم‌هایی مثل رگرسیون خطی، درخت تصمیم، یا شبکه‌های عصبی برای یادگیری رابطه بین ویژگی‌ها و برچسب‌ها.
\item ارزیابی مدل: بررسی عملکرد مدل با معیارهایی مثل دقت
 \lr{(Accuracy)}،
  خطای میانگین مربعات
 \lr{(MSE)}
  یا ماتریس درهم‌ریختگی 
 \lr{(Confusion Matrix)}.
\item یش‌بینی: استفاده از مدل آموزش‌دیده برای پیش‌بینی برچسب داده‌های جدید.
لگوریتم‌های رایج:
- رگرسیون خطی 
\lr{(Linear Regression)}
- رگرسیون لجستیک 
\lr{(Logistic Regression)}
- ماشین بردار پشتیبان 
\lr{(SVM)}
- درخت تصمیم 
\lr{(Decision Tree)}
- جنگل تصادفی
\lr{ (Random Forest)}
- شبکه‌های عصبی 
\lr{(Neural Networks)}\\
\end{itemize}
زایا:
- دقت بالا در صورتی که داده‌های برچسب‌دار کافی و باکیفیت وجود داشته باشد.
- کاربرد گسترده در مسائل واقعی مثل تشخیص پزشکی، پیش‌بینی مالی، و پردازش زبان طبیعی.
چالش‌ها:
- نیاز به داده‌های برچسب‌دار که ممکن است جمع‌آوری آن‌ها زمان‌بر و پرهزینه باشد.
- حساسیت به داده‌های پرت 
\lr{(Outliers)} 
یا نویز.
- خطر بیش‌برازش 
\lr{(Overfitting)} 
اگر مدل بیش از حد به داده‌های آموزشی وابسته شود.\\
مثال عملی:
فرض کنید می‌خواهید یک مدل برای تشخیص تصاویر سگ و گربه بسازید:
داده آموزشی مجموعه‌ای از تصاویر که هر کدام برچسب "سگ" یا "گربه" دارند.
ویژگی‌ها: پیکسل‌های تصویر یا ویژگی‌های استخراج‌شده مثل رنگ و شکل.
آموزش: مدل (مثل یک شبکه کانولوشنی) یاد می‌گیرد که الگوهای مربوط به سگ یا گربه را تشخیص دهد.

\subsection{رگرسیون در یادگیری نظارت شده}
رگرسیون یکی از تکنیک‌های اصلی در یادگیری نظارت‌شده 
\lr{(Supervised Learning)}
 است که برای پیش‌بینی مقادیر پیوسته 
 \lr{(Continuous)}
  استفاده می‌شود. در یادگیری نظارت‌شده، مدل با استفاده از داده‌های ورودی (ویژگی‌ها) و خروجی‌های متناظر (برچسب‌ها) آموزش می‌بیند تا رابطه‌ای بین ورودی‌ها و خروجی‌ها را یاد بگیرد. در مسائل رگرسیون، خروجی یک مقدار عددی پیوسته است، مانند پیش‌بینی قیمت خانه، دمای هوا، یا میزان فروش.
در رگرسیون، متغیر هدف (خروجی) مقداری پیوسته است، برخلاف مسائل طبقه‌بندی که خروجی گسسته (مانند کلاس‌ها) است.
  هدف: یافتن تابعی که رابطه بین ویژگی‌های ورودی ($X$) و خروجی ($y$) را به بهترین شکل مدل کند.\\
  تابع پیش‌بینی: مدل رگرسیون یک تابع $f(X)$ تولید می‌کند که مقادیر پیش‌بینی‌شده ($\hat{y}$) را به ازای ورودی‌های جدید تخمین می‌زند.\\
  خطا: تفاوت بین مقدار واقعی ($y$) و مقدار پیش‌بینی‌شده ($\hat{y}$) به عنوان خطا محاسبه می‌شود. هدف کمینه کردن این خطا است
  
\subsubsection{رگرسیون خطی ساده}
رگرسیون خطی 
\lr{(Linear Regression)}
 یکی از بنیادی‌ترین و پرکاربردترین الگوریتم‌های یادگیری نظارت‌شده در یادگیری ماشین است که برای پیش‌بینی مقادیر پیوسته استفاده می‌شود. در یادگیری نظارت‌شده، هدف یادگیری یک مدل است که رابطه‌ای بین ویژگی‌های ورودی ($  X  $) و خروجی ($  y  $) را با استفاده از داده‌های آموزشی (که شامل جفت‌های $  X, y  $ هستند) مدل‌سازی کند. در رگرسیون خطی، فرض بر این است که رابطه بین ورودی‌ها و خروجی به صورت خطی است. در ادامه، به طور کامل به جنبه‌های مختلف رگرسیون خطی می‌پردازیم\\\\
\textbf{کیمنه سازی:}
تابع هزینه معیاری برای سنجش میزان خطای مدل در پیش‌بینی خروجی‌ها نسبت به مقادیر واقعی است. در رگرسیون خطی، تابع هزینه معمولاً میانگین مربعات خطا 
\lr{(Mean Squared Error - MSE)}
 است که تفاوت بین مقادیر واقعی ($y_i$) و پیش‌بینی‌شده ($\hat{y}_i$) را اندازه‌گیری می‌کند. 
دقت مدل را افزایش دهیم:\\
کمینه کردن تابع هزینه به معنای کاهش خطای پیش‌بینی است. این کار باعث می‌شود مدل پیش‌بینی‌هایی تولید کند که به مقادیر واقعی نزدیک‌تر باشند. پارامترهای بهینه را پیدا کنید.
در رگرسیون خطی، پارامترها (مانند $w_0$ و $w_1$) تعیین‌کننده خط پیش‌بینی هستند. کمینه‌سازی تابع هزینه، مقادیر بهینه این پارامترها را پیدا می‌کند تا مدل بهترین تطابق را با داده‌ها داشته باشد.\\
\textbf{تعمیم مدل} 
با کمینه‌سازی تابع هزینه روی داده‌های آموزشی، مدل می‌تواند الگوهای واقعی داده‌ها را یاد بگیرد و روی داده‌های جدید (داده‌های آزمون) عملکرد بهتری داشته باشد، به شرطی که از بیش‌برازش
\lr {(Overfitting)}
 جلوگیری شود.\\
معیاری برای مقایسه مدل‌ها:
مقدار تابع هزینه می‌تواند به‌عنوان معیاری برای مقایسه عملکرد مدل‌های مختلف (مثلاً رگرسیون خطی در مقابل رگرسیون چندجمله‌ای) استفاده شود.\\
پایه‌ای برای الگوریتم‌های پیچیده‌تر: مفهوم کمینه‌سازی تابع هزینه در رگرسیون خطی، پایه‌ای برای یادگیری الگوریتم‌های پیچیده‌تر مانند شبکه‌های عصبی است که از روش‌های مشابه (مثل گرادیان نزولی) برای بهینه‌سازی استفاده می‌کنند.\\
\textbf{اثبات کمینه‌سازی تابع هزینه در رگرسیون خطی}
 \begin{equation}
   J(w_0, w_1)=\sum_{i=1}^n (y_i^{(i)} - \hat{y}^{(i)})^2  = \sum_{i=1}^n (y_i^{(i)} - (w_0 + w_1x_i^{(i)}))^2 
 \end{equation}
 که در آن \( y_i \) مقدار واقعی، \( \hat{y}_i = w_0 + w_1x_i \) مقدار پیش‌بینی‌شده. می باشد.\\
 \textbf{کمینه‌سازی تابع هزینه}
 برای کمینه کردن \( J(w_0, w_1) \)، مشتق‌های جزئی نسبت به \( w_0 \) و \( w_1 \) را محاسبه و صفر می‌کنیم.\\
 \subsubsection*{مشتق نسبت به \( w_0 \)}
 \[
 \frac{\partial J}{\partial w_0} = \frac{\partial}{\partial w_0} \left[ \sum_{i=1}^n (y_i^{(i)} - (w_0 + w_1x_i^{(i)}))^2\right]
 \]
 \[
 -2 \sum_{i=1}^n (y_i^{(i)} - w_0 - w_1x_i^{(i)})^2=0
 \]

 \[
 n w_0 + w_1 \sum_{i=1}^n x_i = \sum_{i=1}^n y_i
 \]
 
 \[
 w_0 = \frac{\sum_{i=1}^n y_i - w_1 \sum_{i=1}^n x_i}{n} = \bar{y} - w_1 \bar{x}
 \]
 که در آن \( \bar{x} = \frac{\sum x_i}{n} \) و \( \bar{y} = \frac{\sum y_i}{n} \) میانگین داده‌ها هستند.
 
 \subsubsection*{مشتق نسبت به \( w_1 \)}
 \[
 \frac{\partial J}{\partial w_1} = \frac{\partial}{\partial w_1} \left[ \sum_{i=1}^n (y_i^{(i)} - (w_0 + w_1x_i^{(i)}))^2 \right]
 \]
 \[
  =\sum_{i=1}^n 2 (y_i^{(i)} - w_0 - w_1x_i^{(i)}) (-x_i^{(i)}) = \sum_{i=1}^n x_i (y_i^{(i)} - w_0 - w_1x_i^{(i)})
 \]
 صفر کردن مشتق و جایگذاری \( w_0 = \bar{y} - w_1 \bar{x} \):
 \[
 \sum_{i=1}^n x_i^{(i)} \left( y_i^{(i)} - (\bar{y} - w_1 \bar{x}) - w_1 x_i^{(i)} \right) = 0
 \]
 \[
 \sum_{i=1}^n x_i^{(i)} (y_i^{(i)} - \bar{y} - w_1 (x_i^{(i)} - \bar{x})) = 0
 \]
 \[
 \sum_{i=1}^n x_i^{(i)} (y_i^{(i)} - \bar{y}) - w_1 \sum_{i=1}^n x_i (x_i^{(i)} - \bar{x}) = 0
 \]
 حل برای \( w_1 \):
 \[
 w_1 = \frac{\sum_{i=1}^n x_i^{(i)} (y_i^{(i)} - \bar{y})}{\sum_{i=1}^n x_i^{(i)} (x_i^{(i)} - \bar{x})}
 \]
 برای ساده‌سازی، از فرم معادل استفاده می‌کنیم:
 \[
 w_1 = \frac{\sum_{i=1}^n (x_i^{(i)} - \bar{x})(y_i^{(i)} - \bar{y})}{\sum_{i=1}^n (x_i^{(i)} - \bar{x})^2}
 \]
 \textbf{برآوردگرهای بهینه}
 بنابراین، برآوردگرهای بهینه برای پارامترها عبارت‌اند از:
 \begin{equation}
 	\hat{w_1} = \frac{\sum_{i=1}^n (x_i^{(i)} - \bar{x})(y_i^{(i)} - \bar{y})}{\sum_{i=1}^n (x_i^{(i)} - \bar{x})^2}
 \end{equation}
 \begin{equation}
 	\hat{w_0} = \bar{y} - w_1 \bar{x}
 \end{equation}
\subsubsection{رگرسیون خطی چند متغیره}
  رگرسیون خطی چندگانه
\lr{(Multiple Linear Regression)} 
  یکی از روش‌های کلیدی در یادگیری نظارت‌شده است که برای پیش‌بینی یک متغیر وابسته (خروجی پیوسته) بر اساس چندین متغیر مستقل (ویژگی‌ها) استفاده می‌شود. این روش زمانی کاربرد دارد که بخواهیم رابطه‌ای خطی بین چندین متغیر ورودی و یک خروجی پیوسته را مدل کنیم. در یادگیری نظارت‌شده، داده‌های آموزشی شامل جفت‌های ورودی (ویژگی‌ها) و خروجی (برچسب‌ها) هستند، و رگرسیون خطی چندگانه با یادگیری این رابطه، پیش‌بینی‌های دقیقی برای داده‌های جدید ارائه می‌دهد. در ادامه، به کاربردهای این روش و فرضیات آن می‌پردازیم.\\
رگرسیون چندگانه به ما کمک می‌کند تا اثر هر متغیر مستقل بر خروجی را درک کنیم. ضرایب مدل نشان‌دهنده میزان تأثیر هر ویژگی هستند.\\
مثال: در بازاریابی، می‌توان تأثیر بودجه تبلیغات، نوع رسانه، و فصل فروش بر میزان فروش را بررسی کرد.\\
کاربردهای گسترده در حوزه‌های مختلف:\\
اقتصاد: پیش‌بینی رشد اقتصادی یا تورم بر اساس متغیرهایی مانند نرخ بهره، تولید ناخالص داخلی، و بیکاری.\\
پزشکی: پیش‌بینی فشار خون بیمار بر اساس سن، وزن، سطح فعالیت بدنی، و رژیم غذایی.\\
علوم طبیعی: پیش‌بینی دمای هوا با استفاده از متغیرهایی مانند رطوبت، فشار جو، و سرعت باد.\\
بازاریابی و تجارت: پیش‌بینی فروش محصول بر اساس قیمت، تبلیغات، و رفتار مشتری.\\
مهندسی: پیش‌بینی مصرف انرژی یک ساختمان بر اساس اندازه، تعداد ساکنان، و نوع عایق‌بندی.
پایه‌ای برای مدل‌های پیچیده‌تر:\\
رگرسیون خطی چندگانه به دلیل سادگی و تفسیرپذیری، پایه‌ای برای درک مدل‌های پیشرفته‌تر مانند رگرسیون منظم‌شده (ریج، لاسو) یا شبکه‌های عصبی است.\\
این روش به‌عنوان یک معیار اولیه 
 \lr{(Baseline)}  
 برای مقایسه با مدل‌های پیچیده‌تر استفاده می‌شود.\\
 تصمیم‌گیری مبتنی بر داده:\\
 با ارائه پیش‌بینی‌های دقیق، رگرسیون چندگانه به تصمیم‌گیری در حوزه‌هایی مانند مدیریت ریسک، برنامه‌ریزی مالی، و بهینه‌سازی منابع کمک می‌کند.\\
 مثال: پیش‌بینی تقاضای محصول برای مدیریت موجودی در زنجیره تأمین.\\
 تحلیل روابط پیچیده:\\
 این روش امکان مدل‌سازی تعاملات بین متغیرهای مختلف را فراهم می‌کند، به‌ویژه زمانی که یک متغیر به‌تنهایی نمی‌تواند خروجی را توضیح دهد.\\
  مثال: پیش‌بینی عملکرد تحصیلی دانش‌آموز بر اساس ساعات مطالعه، کیفیت تدریس، و سطح استرس.
  \textbf{کمینه‌سازی تابع هزینه در رگرسیون خطی چندگانه}\\
  رگرسیون خطی چندگانه رابطه بین متغیر وابسته (\(y\)) و چندین متغیر مستقل (\(x_1, x_2, \dots, x_n\)) را به صورت زیر مدل می‌کند:
  \begin{equation}
  	y = w_0 + w_1x_1 + w_2x_2 + \dots + w_nx_n
  \end{equation}
  به صورت ماتریسی: \( y = Xw \)، که در آن:
  \begin{itemize}[label={\color{black}$\bullet$}]
  	\item \( X = [1, x_1, x_2, \dots, x_n] \): ماتریس ویژگی‌ها (ستون اول برای \( w_0 \) پر از ۱ است).
  	\item \( w = [w_0, w_1, \dots, w_n]^T \): بردار ضرایب.
  	\item \( y \): بردار خروجی‌ها.
  \end{itemize}
  \textbf{تابع هزینه}
  تابع هزینه میانگین مربعات خطا
   \lr{(MSE)} 
   به صورت زیر تعریف می‌شود:
  
  \begin{equation}
  	J(w) = \frac{1}{n} \sum_{i=1}^n (y_i - (w_0 + w_1x_{i1} + \dots + w_nx_{in}))^2
  \end{equation}
  یا به صورت ماتریسی:
  \begin{equation}
  	J(w) = \frac{1}{n} (y - Xw)^T (y - Xw)
  \end{equation}
  \textbf{کمینه سازی رگرسیون چند جمله ای}
  برای کمینه‌سازی \( J(w) \)، مشتق تابع هزینه نسبت به \( w \) محاسبه و صفر می‌شود.
  تابع هزینه را گسترش می‌دهیم:\\
  \[
  J(w) = \frac{1}{n} \left[ (y^T y - 2 y^T X w + w^T X^T X w) \right]
  \]
  مشتق نسبت به \( w \):
  
  \begin{equation}
  	\frac{\partial J}{\partial w} = \frac{\partial}{\partial w} \left[ \frac{1}{n} (y^T y - 2 y^T X w + w^T X^T X w) \right]
  \end{equation}
  
  \[
  = \frac{1}{n} \left( -2 X^T y + 2 X^T X w \right) = \frac{2}{n} \left( X^T X w - X^T y \right)
  \] 
  صفر کردن مشتق:
  \begin{equation}
  	X^T X w = X^T y
  \end{equation}
برآوردگر \( w \):
  \begin{equation}
  	\hat{w} = (X^T X)^{-1} X^T y
  \end{equation}
این برآوردگر بهینه، تابع هزینه را کمینه می‌کند، مشروط بر اینکه \( X^T X \) معکوس‌پذیر باشد (یعنی ویژگی‌ها هم‌خطی کامل نداشته باشند).\\
 \textbf{تعمیم حالت خطی.}
 \begin{figure}[t]
 	\centering
 	\includegraphics[width=0.5\textwidth]{best_fitted_line.png}
 	\caption{استفاده از رگرسیون خطی با که باعث نویز شده است.}
 	\label{fig:my_label}
 \end{figure}
 \ref{fig:sample}
رگرسیون خطی ساده
\lr{(Simple Linear Regression)}
برای مدل‌سازی رابطه بین یک متغیر مستقل ($x$) و یک متغیر وابسته ($y$) به کار می‌رود، اما در بسیاری از مسائل واقعی، خروجی ($y$) تحت تأثیر چندین متغیر مستقل است. در چنین مواردی، رگرسیون خطی چندگانه 
\lr{(Multiple Linear Regression)}
به دلیل توانایی در نظر گرفتن چندین متغیر مستقل به طور همزمان، انتخاب مناسب‌تری است. در ادامه، به دلایل اصلی استفاده از رگرسیون چندگانه به جای رگرسیون خطی ساده،   استفاده خواهد شد.\\
 همان طوری که در بالا هم مشاهده می شود وقتی از رگرسیون خطی روی داده های چند گانه می شود باعث این می شود یک نویز یا خطایی به وجود آید حتی برای آن یک تخمین اولیه را نداشته باشیم. 
برای رفع این مشل می توانیم از رگرسیون های چند گانه با درجه هایی مختلفی استفاه کنیم و این نویز را از بیین ببریم. به تصویر عدی نگاه کنید. \\
همان طور که در تصویر بالا مشاهده می شود زمانی که درجه را زیاد می کنیم باعث می شود که نمودار به سمت چند جمله برود در نهایت خطایی مدل ما خیلی کاهش یابد و از  
\lr{overfit}
جلوگیری شود. 
نکته ای باید مد نظر داشته باشید شما می توانید از چند تبدیل های مخلتفی استفاده کنید و بهترین برارزش را برای داده خود انجام دهید. در ادامه به برخی از از تبدیل ها اشاره خواهیم کرد. \\ \\
\textbf{:انواع تبدیل‌ها}
\begin{itemize}[label={\color{black}$\bullet$}]
	\item تبدیل لگاریتمی: \( y' = \log(y) \) یا \( x_i' = \log(x_i) \). برای داده‌های با توزیع کج یا روابط نمایی.
	\item تبدیل چندجمله‌ای: \( x_i' = x_i^2, x_i^3, \dots \). برای مدل‌سازی روابط غیرخطی.
	\item تبدیل ریشه مربع: \( y' = \sqrt{y} \) یا \( x_i' = \sqrt{x_i} \). برای کاهش کجی یا اثر مقادیر بزرگ.
	\item تبدیل معکوس: \( y' = \frac{1}{y} \). برای روابط معکوس یا مدیریت داده‌های پرت.
\end{itemize}
 \begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{best_fitted_polynomial}
	\caption{استفاده نمودار غیر خطی .}
	\label{fig:my_label}
\end{figure}
از جمله تبدیل های هستند که می توانید برای برزاش داده استفاده کنید از 
\lr{overfit}
و
\lr{underfit}
شدن جلوگیری کنید.\\
\subsubsection{گرادیان(\lr{gradeint})}
گرادیان نزولی 
\lr{(Gradient Descent)}
 یکی از الگوریتم‌های بهینه‌سازی پرکاربرد در یادگیری ماشین است که برای کمینه‌سازی تابع هزینه
\lr{(Cost Function)}
  در مدل‌هایی مانند رگرسیون خطی، رگرسیون لجستیک، و شبکه‌های عصبی استفاده می‌شود. این روش به‌ویژه در مواردی که داده‌ها حجم زیادی دارند یا محاسبات تحلیلی (مانند روش حداقل مربعات) هزینه‌بر هستند، بسیار مفید است. در ادامه، توضیح جامعی درباره گرادیان نزولی، نحوه کار، انواع آن، کاربردها، و مزایا و معایب آن ارائه می‌شود.
گرادیان نزولی یک الگوریتم تکراری است که برای یافتن مقادیر بهینه پارامترهای مدل مانند ( $ w_0, w_1, \dots $) به‌گونه‌ای که تابع هزینه ($ J(w) $) کمینه شود، استفاده می‌شود. ایده اصلی این است که با حرکت در جهت مخالف گرادیان (مشتق تابع هزینه)، به سمت نقطه کمینه حرکت کنیم.\\
گرادیان: بردار مشتق‌های جزئی تابع هزینه نسبت به پارامترها، که جهت و شدت تغییرات تابع هزینه را نشان می‌دهد.\\
نزولی: حرکت در جهت مخالف گرادیان برای کاهش مقدار تابع هزینه.\\
شروع با مقادیر اولیه: مقادیر اولیه تصادفی یا صفر برای پارامترها ($ w $) انتخاب می‌شود.
محاسبه گرادیان: مشتق جزئی تابع هزینه نسبت به هر پارامتر محاسبه می‌شود:
$$\frac{\partial J}{\partial w_j}$$\\
به‌روزرسانی پارامترها: پارامترها در جهت مخالف گرادیان با گام مشخص (نرخ یادگیری، $ \alpha $) به‌روزرسانی می‌شوند:
$$w_j := w_j - \alpha \frac{\partial J}{\partial w_j}$$
تکرار : مراحل بالا تا زمانی تکرار می‌شود که تابع هزینه به مقدار کمینه برسد یا تغییرات آن ناچیز شود (همگرایی).\\ \\ 
\textbf{انواع گرادیان}\\
 گرادیان نزولی بر اساس نحوه استفاده از داده‌ها به سه نوع اصلی تقسیم می‌شود:\\
$1$. گرادیان نزولی دسته‌ای
\lr{(Batch Gradient Descent)}:
 گرادیان با استفاده از کل داده‌های آموزشی محاسبه می‌شود.\\
مزایا : همگرایی پایدارتر به سمت کمینه.
معایب : برای داده‌های بزرگ، محاسبات سنگین و کند است.\\
$2$. گرادیان نزولی تصادفی 
\lr{(Stochastic Gradient Descent - SGD)}:
گرادیان برای هر نمونه داده به‌صورت جداگانه محاسبه و پارامترها به‌روزرسانی می‌شوند.\\
مزایا : سریع‌تر برای داده‌های بزرگ، می‌تواند از کمینه‌های محلی فرار کند.
معایب: نوسانات زیاد در تابع هزینه، ممکن است به کمینه دقیق نرسد.\\
$3$. گرادیان نزولی مینی‌بچ 
\lr{(Mini-Batch Gradient Descent)}:
داده‌ها به دسته‌های کوچک 
\lr{(mini-Batches) }
تقسیم می‌شوند و گرادیان برای هر دسته محاسبه می‌شود.
مزایا: تعادل بین سرعت و پایداری، پرکاربرد در شبکه‌های عصبی.
معایب: نیاز به تنظیم اندازه دسته.\\
\textbf{کاربرد گرادیان نزولی در رگرسیون خطی}
در رگرسیون خطی، تابع هزینه معمولاً میانگین مربعات خطا
 \lr{(MSE)} 
 است:
$$J(w) = \frac{1}{n} \sum_{i=1}^n (y_i - (w_0 + w_1x_{i1} + \dots + w_nx_{in}))^2$$
گرادیان نزولی برای یافتن $ w_0, w_1, \dots, w_n $ استفاده می‌شود:\\
مشتق‌های جزئی:
$$\frac{\partial J}{\partial w_0} = -\frac{2}{n} \sum_{i=1}^n (y_i - \hat{y}_i)$$
$$\frac{\partial J}{\partial w_j} = -\frac{2}{n} \sum_{i=1}^n (y_i - \hat{y}_i) x_{ij}, \quad j = 1, \dots, n$$
به‌روزرسانی:\\
$$w_j := w_j + \alpha \frac{2}{n} \sum_{i=1}^n (y_i - \hat{y}_i) x_{ij}$$\\\\\\
\vspace*{1cm}
 \begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{gd1.png}
	\caption{گرادیان کاهشی}
	\label{fig:my_label}
\end{figure}
\lr{cost function}
در این  نمودار یک سطح سه بعدی است که محورهای آن به صورت زیر تعریف شده‌اند:
\begin{itemize}[label={\color{black}$\bullet$}]
\item\text{محور $x$: $\theta_0$ (پارامتر اول، مثلاً $w_0$).}
\item \text{محور $y$: $\theta_1$ (پارامتر دوم، مثلاً $w_1$).}
\item \text{محور هر نمودار یک سطح سه ‌بعدی است که محورهای آن به صورت زیر تعریف شده‌اند:}\\
\end{itemize}
محور $x$: $\theta_0$ (پارامتر اول، مثلاً $w_0$). 
محور $y$: $\theta_1$ (پارامتر دوم، مثلاً $w_1$).
محور $z$: $J(\theta_0, \theta_1)$ (مقدار تابع هزینه).\\
نمودار سمت چپ: مسیر گرادیان نزولی با نرخ یادگیری ($\alpha$) بالاتر یا تعداد مراحل کمتر نشان داده شده است. مسیر دارای انحنا و نوسانات بیشتری است و به نظر می‌رسد هنوز به کمینه دقیق نرسیده است.\\
نمودار سمت راست: مسیر صاف‌تر و مستقیم‌تر است، که نشان‌دهنده نرخ یادگیری مناسب‌تر یا تعداد مراحل بیشتر است. این مسیر به طور واضح به سمت کمینه همگرا شده است.\\
\subsubsection{رگرسیون لجستیک}

می توان تابع لجستیک را به این شکل تعریف کرد. 
\[
\hat{Y}=\sigma (z)=\sigma(x_{0}w_{0} +x_{1}w_{1}+...+x_{n}w_{n})\\
\]
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{sigmodfunctiongrapik.png}
    \caption{تابع لجسیتک در یادگیری ماشین}
	\label{fig:my_label}
\end{figure}
\vspace{1cm}
تابع سیگومد به این شکل می باشد.\\
\[
\sigma(z)=\frac{1}{1+e^{-z}}\\
\]
و همچنین در مورد مشقق پذیری 
	\begin{align*}
		\lim_{z \rightarrow -\infty} \sigma(x)= \frac{1}{1 + {\infty}}=0 &\\
		\lim_{z \rightarrow \infty} \sigma(x)= \frac{1}{1+0}=1&\\
		\lim_{z \rightarrow 0} \sigma(x)= \frac{1}{1+1}=0.5\\
	\end{align*}
از آن جایی که 
$-\infty<x<\infty$
پس می توان نوشت 
$0< \sigma (z)<1$
می باشد. 
و  نمودار به شکل زیر می باشد \\
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{functionsigmod.jpg}
	\caption{نمودار تابع لجسیتک}
	\label{fig:my_label}
\end{figure}
\vspace{1cm}
\!\!\!\!\!\!\!\!\!
یکی دیگر از ویژگی های خوبی که این تابع دارد متشق پذیر است.
\begin{align*}
 \frac{\partial}{\partial z}(\frac{1}{(1+e^{-z})})= - \frac{e^{-z}}{(1+e^{-z})}\frac{1}{1+\sigma^{-z}}=(\sigma(z)) (1-\sigma(z))
\end{align*}
در یادگیری ماشین ما نیاز داریم که عددی که یا پیش بینی های که به ما باز گرداننده می شوند یک عدد بین صفر و یک باشد که برای همین می توان از تابع لجسیتیک به شکل نووشت:
\begin{align*}
&p(y=1 | x,w)=\sigma(w^{T} x)\\
&p(y=0 | x,w)=(1-\sigma(w^{T} x))
\end{align*}
\textbf{به‌دست آوردن تابع هزینه در رگرسیون لجستیک} 	
 \[
 P(y_i = 1 \mid x_i; w) = \sigma(w^\top x_i) = \frac{1}{1 + e^{-w^\top x_i}}
 \]
	برای \( y_i \in \{0, 1\} \)، توزیع برنولی را داریم:
	\[
P(y_i \mid x_i; w) = \sigma(w^\top x_i)^{y_i} \cdot (1 - \sigma(w^\top x_i))^{1 - y_i}
\]
با فرض مستقل بودن مشاهدات، تابع درست‌نمایی برابر است با:
\[
L(w) = \prod_{i=1}^n \sigma(w^\top x_i)^{y_i} \cdot (1 - \sigma(w^\top x_i))^{1 - y_i}
\]
برای ساده‌سازی، لگاریتم تابع درست‌نمایی را می‌گیریم:
\[
\ell(w) = \log L(w) = \sum_{i=1}^n \left[ y_i \log \sigma(w^\top x_i) + (1 - y_i) \log(1 - \sigma(w^\top x_i)) \right]
\]
حال برای پیدا کردن بردار وزن بهینه \( w \)، گرادیان تابع لگاریتم درست‌نمایی را محاسبه می‌کنیم:
\[
\nabla_w \ell(w) = \sum_{i=1}^n (y_i - \sigma(w^\top x_i)) x_i
\]
این تابع شبیه به رگرسیون نیست که با استفاده از فرم بسته بتوان برای
\lr{w}
پیدا کرد. پس با استفاده از گرایان مقدار بهینه را برای پارامتر پیدا خواهیم کرد. \\
برای بیشینه‌سازی تابع درست‌نمایی، از الگوریتم‌های عددی مانند گرادیان افزایشی
\lr{(Gradient Ascent)}
 یا گرادیان کاهشی 
\lr{(Gradient Descent)}
استفاده می‌شود. در عمل، ما معمولاً گرادیان کاهشی را برای کمینه‌سازی تابع هزینه معادل استفاده می‌کنیم:

\[
J(w) = -\ell(w) = - \sum_{i=1}^n \left[ y_i \log \sigma(w^\top x_i) + (1 - y_i) \log(1 - \sigma(w^\top x_i)) \right]
\]
مشتق منفی آن نیز همان است:

\[
\nabla_w J(w) = -\sum_{i=1}^n (y_i - \sigma(w^\top x_i)) x_i
\]
\subsubsection{نظم‌دهی \lr{(Regularization)}}
یک تکینک مهم در ماشین لرنینگ است که باعث کاهش کمینه کردن و بهبود دقت می شود، با جلوگیری از بیش ‌برازش 
\lr{(Overfitting-)}
حذف داده های پردت و باعث کاهش نویز می شود و کمک می کند مدل ساده تر شود و روی داده های جدید به خوبی عمل می کند. ابن عمل فقط با افزون یک ترم یا جریمه صورت خواهدد گرفت.
\\
\textbf{انواع\lr{(Regularization)}}
مدلی رگرسیونی که از تکنیک نظم‌دهی 
\lr{L1} استفاده می‌کند، رگرسیون لاسو
\lr{(LASSO)}
  نام دارد که مخفف
(\lr{Least Absolute Shrinkage and Selection Operator})
   است.
در این روش، مقدار قدر مطلق ضرایب (ضریب‌های مدل) به‌عنوان یک جریمه
(\lr{penalty})
  به تابع زیان
(\lr{L})
    اضافه می‌شود.
این جریمه می‌تواند باعث شود برخی ضرایب کاملاً به صفر برسند، که در نتیجه ویژگی‌های کم‌اهمیت حذف شده و تنها ویژگی‌های مهم باقی می‌مانند.
\subsubsection{رگرسیون لاسو }
\lr{Lasso Regression}
 یک روش رگرسیونی مبتنی بر تکنیک "کوچک‌سازی و انتخاب بر اساس قدر مطلق
  است که در تحلیل رگرسیون برای انتخاب متغیرها و اعمال نظم‌دهی 
\lr{Regularization}
 استفاده می‌شود.
این روش به حذف ویژگی‌های غیرمرتبط داده کمک می‌کند و از بیش‌برازش
\lr{Overfitting}
  جلوگیری می‌کند.
در نتیجه، ویژگی‌هایی که تأثیر ضعیفی دارند به‌خوبی مشخص می‌شوند، چرا که ضرایب متغیرهای کم‌اهمیت به سمت صفر میل می‌کنند.
در حقیقت می‌توان گفت که رگرسیون لاسو یکی از روش‌هایی است که با افزودن یک جمله‌ی جریمه به تابع هزینه مدل خطی، از بیش‌برازش جلوگیری می‌کند. تابع هزینه در این روش به صورت زیر تعریف می‌شود:
\[
J(w)=\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y_i}) +\lambda \sum_{i=1}^{m}|w_i|
\]
و همچنین در فرمول بالا $min Rss =\sum (y_i -\hat{y_i})^2$\\
$y$= مقدار مشاهده شده.\\
$\hat{y}$= مقدار پاسخ بیش بینی شده\\
و در قسمت جمله جریمه
(\lr {penalty prem})
$\lambda \sum |w|$  این تابع مشتق پذیر نمی باشد.\\
$w$=  ضرایب\\
$\lambda $ یک پارامتر تنظیم 
(\lr{uning parameter})
 است که شدت جریمه 
(\lr {penalty}) 
 را کنترل می‌کند. هرچه مقدار $\lambda$ بیشتر شود، ضرایب بیشتری به سمت صفر رانده می‌شوند.\\
 و می توان به شکل زیر فرمول بالا را بازنویسی کرد:
 \[
 J(w)= min\,\,RSS + \lambda \sum_{i=1}^{m} |w_i|
 \]
 \textbf{تنظیم مقدار بهینه لاندا}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{r1.png}
	\caption{\lr{biase and varince in lasso}}
	\label{fig:my_label}
\end{figure}
در ادامه دو معیار مهم در ماشین لرنینگ را مورد بررسی قرار خواهیم داد.\\ 
\lr{Bias}= وقتی یک مدل بسیار ساده باشد و داده های ما پیچده باشند نقاط پرت زیاد می شوند در نهایت خطا افزایش می یابد. \\
\lr{variance}= در حقیقت وقتی مدل پیچیده باشد می تواند تنها روی داده های آموزش یا داده تست به خوبی فیت شود و در حالی در برگیرنده داده های آموزش نیست در نهایت می توان گفت که واریانس زیاد شده و اورفیت رخ داده است. \\
\lr{panlty}= کاربردی که دارد باعث می شود ویژگی های که اهمیت کمی دارند حذف شوند. و این عمل باعث کاهش واریانس می شود و از اورفیت شدن جلوگیری میکند. 
\textbf{افزایش مقدار $\lambda$}
باعث این می شود مدل بیش از حد ساده باشد و در نهایت باع ث این میشود که 
\lr{underfit}
 رخ دهد. 
برای رسیدن به تعادل درست بین 
\lr{Bias}
 و
\lr{Variance} 
 باید مقدار مناسب $\lambda$ را با استفاده از 
\lr {cross-validation}
  پیدا کرد.\\
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{r2.png}
	\caption{\lr{cost function}}
	\label{fig:my_label}
\end{figure}
\!\!\!\!\!\!\!\!در نمودار مربوط به \lr{Lasso Regression}، تابع هزینه به‌صورت ترکیبی از مجموع مربعات باقیمانده‌ها (\lr{Residual Sum of Squares} یا \lr{RSS}) و یک جریمه‌ی \lr{L1} بر ضرایب \(\beta_j\) تعریف می‌شود. بخش اول یعنی \lr{RSS}، اختلاف مربعی بین مقادیر واقعی و مقادیر پیش‌بینی‌شده را اندازه‌گیری می‌کند. بخش دوم، یعنی جریمه‌ی \lr{L1} (یا \lr{L1 penalty})، مقدار قدر مطلق ضرایب را جریمه می‌کند و باعث می‌شود برخی از ضرایب به صفر نزدیک شوند یا دقیقاً صفر شوند. این امر باعث ساده‌تر شدن مدل می‌گردد. شدت اثر این جریمه توسط پارامتر \(\lambda\) (یعنی \lr{lambda}) کنترل می‌شود.\\
در نمودار، محور عمودی (محور \lr{y}) مقدار تابع هزینه را نشان می‌دهد که \lr{Lasso Regression} تلاش می‌کند آن را کمینه کند، و محور افقی (محور \lr{x}) مقدار پارامتر \(\lambda\) را نمایش می‌دهد که شدت جریمه‌ی \lr{L1} را مشخص می‌کند. منحنی‌ای که از رنگ سبز به نارنجی تغییر می‌کند، نشان‌دهنده‌ی تغییرات مقدار تابع هزینه نسبت به تغییرات \(\lambda\) است. با افزایش \(\lambda\)، مقدار جریمه بیشتر شده و در نتیجه مقدار تابع هزینه نیز افزایش می‌یابد. این افزایش موجب می‌شود ضرایب بیشتری به سمت صفر رانده شوند و در نتیجه مدل ساده‌تر شود.\\
\subsubsection{رگرسیون ریچ}
رگرسیون ریچ یک 
\lr{regularized}
است از رگرسسیون خطی. وبا اضافه کردن یک تابع جریمه به 
\lr{cost function}
کمک می کند یک به نقطه بهینه برسیم و هم چنین $overfit$ کمتری رخ بدهد. 
\[J(\theta)=MSE(\theta) + \alpha \sum_{i}^{n} \theta _i ^2\]
نکته: در رگرسیو ریچ به این مورد توجه کنید که ویژگی های که اهیمت کمی دارند کوچیک می شوند یا نزیدک به صفر. 
نکته: از این ترم
 $\alpha \sum_{i=1}^{n} \theta_i^2$
 استفاده می شود. \\
 نکته: برای این که معیار عمل کرد مدل را تشخیص دهیم. یعنی وقتی که مدل را استفاده از تست دیتا عملکرد آن را مورد سیجش قرار می دهیم از این ترم استفاده خواهیم 
 $j(\theta)=MSE(\theta)$
 این قسمت برای این که متشق پذیر است و گرادیان آن راحت حساب می شود از آن استفاده خواهیم کرد. \\\\\\\\
\textbf{توان منظم‌دهی (\lr{Regularization strength})}
با آلفا ($\alpha$) مشخص می‌شود که یکی از \lr{hyperparameter}‌ و دو ویژگی دارد:
\\
$1.$ اگر $\alpha = 0$ باشد، هیچ منظم‌‌دهی اعمال نمی‌شود و مدل به رگرسیون خطی استاندارد (\lr{OLS}) تبدیل می‌شود.

 \subsection{یادگیری بدون نظارت}
 تعریف ...یادگیری بدون نظارت 
 \lr{(Unsupervised Learning)}
 به تحلیل داده‌های بدون برچسب برای کشف الگوها یا ساختارهای مخفی در داده‌ها اشاره دارد
 \subsubsection{\lr{K-means}}
 \begin{enumerate}
 	\item \textbf{خوشه‌بندی \lr{(Clustering)}:} 
 	\begin{itemize}[label={\color{black}$\bullet$}]
 		\item داده‌ها را بر اساس شباهت به گروه‌هایی تقسیم می‌کند.
 		\item نقاط داده در یک خوشه به یکدیگر شبیه‌ترند تا به نقاط خوشه‌های دیگر.
 		\item شباهت بسته به نوع مسئله تعریف می‌شود (مثلاً رفتار خرید در تقسیم‌بندی بازار).
 	\end{itemize}
 	\item \textbf{کاهش ابعاد 
 		\lr{(Dimensionality Reduction):}}
 	\begin{itemize}[label={\color{black}$\bullet$}]
 		\item تعداد ویژگی‌های داده را کاهش می‌دهد، اما ویژگی‌های مهم و اطلاعاتی را حفظ می‌کند.
 	\end{itemize}
 	\item \textbf{تشخیص ناهنجاری \lr{(Anomaly Detection)}:}
 	\begin{itemize}[label={\color{black}$\bullet$}]
 		\item شناسایی نقاط داده‌ای که به طور قابل‌توجهی از حالت عادی منحرف هستند (مثلاً تشخیص تقلب).
 	\end{itemize}
 	\item \textbf{مدل‌سازی مولد \lr{(Generative Modeling)}:}
 	\begin{itemize}[label={\color{black}$\bullet$}]
 		\item یادگیری توزیع داده‌ها برای تولید نمونه‌های جدید و مشابه.
 	\end{itemize}
 \end{enumerate}
 \textbf{کاربردهای خوشه‌بندی}
 \begin{itemize}[label={\color{black}$\bullet$}]
 	\item \textbf{تقسیم‌بندی مشتریان \lr{(Customer Segmentation)}:} در بازاریابی برای گروه‌بندی مشتریان بر اساس رفتار.
 	\item \textbf{تقسیم‌بندی تصویر و تشخیص اشیا \lr{(Image Segmentation and Object Detection)}:} در بینایی کامپیوتری.
 	\item \textbf{تشخیص ناهنجاری:} در امنیت سایبری و امور مالی.
 	\item \textbf{ژنتیک و بیوانفورماتیک:} تحلیل داده‌های زیستی.
 	\item \textbf{تحلیل شبکه‌های اجتماعی و تشخیص جوامع:} شناسایی گروه‌های مشابه در شبکه‌ها.
 \end{itemize}
 \textbf{الگوریتم خوشه‌بندی \lr{K-Means}}
 \begin{itemize}[label={\color{black}$\bullet$}]
 	\item پرکاربردترین الگوریتم خوشه‌بندی.
 	\item داده‌ها را به \textbf{\lr{K}} گروه مجزا بر اساس شباهت ویژگی‌ها تقسیم می‌کند.
 	\item با تخصیص تکراری نقاط داده به نزدیک‌ترین مرکز (میانگین گروه) کار می‌کند و سپس مراکز را بر اساس عضویت‌های جدید گروه‌ها بازمحاسبه می‌کند.
 	\item این فرآیند تا زمانی که تخصیص‌ها دیگر تغییر نکنند، تکرار می‌شود.
 \end{itemize}
 \begin{figure}[h]
 	\centering
 	\begin{subfigure}{.19\textwidth}
 		\includegraphics[width=\linewidth]{kmeans_iter_1}
 	\end{subfigure}
 	\begin{subfigure}{.19\textwidth}
 		\includegraphics[width=\linewidth]{kmeans_iter_2}
 	\end{subfigure}
 	\begin{subfigure}{.19\textwidth}
 		\includegraphics[width=\linewidth]{kmeans_iter_3}
 	\end{subfigure}
 	\begin{subfigure}{.19\textwidth}
 		\includegraphics[width=\linewidth]{kmeans_iter_4}
 	\end{subfigure}
 	\begin{subfigure}{.19\textwidth}
 		\includegraphics[width=\linewidth]{kmeans_iter_5}
 	\end{subfigure}
 	\caption{\lr{K-means}}
 \end{figure}
 \vspace*{1cm}
 \begin{itemize}[label={\color{black}$\bullet$}]
 	\item هدف: نقاط داده در یک خوشه باید به یکدیگر شبیه باشند.
 	\item در \lr{K-Means}، این هدف به‌صورت تابع هزینه زیر بیان می‌شود:
 	\[
 	J = \sum_{j=1}^{K} \sum_{x^{(i)} \in C_j} \|x^{(i)} - \mu_j\|^2
 	\]
 	\item انتخاب $f$ و $\mu = \{\mu_1, \mu_2, \dots, \mu_K\}$ برای کمینه کردن تابع $J$.
 	\item این مسئله 
 	\lr{NP-hard}
 	است. الگوریتم
 	\lr{K-Means}
 	یک راه‌حل هیوریستیک است که تضمین نمی‌کند حتماً به راه‌حل بهینه برسد.
 \end{itemize}
 
 \begin{itemize}[label={\color{black}$\bullet$}]
 	\item ابتدا هر نمونه به نزدیک‌ترین مرکز تخصیص داده می‌شود:
 	\[
 	f(x) := \arg\min_j \|x - \mu_j\|^2
 	\]
 	\item تخصیص هر نمونه تا زمانی که مرکز نزدیک‌تری پیدا نشود، ثابت می‌ماند.
 	\item هر بار که یک نمونه بازتخصیص می‌شود، مجموع فاصله بین نمونه‌ها و مراکز آن‌ها کاهش می‌یابد.
 	\item تعداد تخصیص‌های ممکن نمونه به مرکز محدود است.
 	\item الگوریتم زمانی خاتمه می‌یابد که هیچ نمونه‌ای مرکز تخصیص‌یافته خود را تغییر ندهد.
 	\item در مرحله به‌روزرسانی، با ثابت نگه داشتن $f(x)$، تابع $J$ به‌صورت یک تابع درجه دوم از $\mu_j$ (مانند مجموع مربعات خطا) است و با مشتق‌گیری می‌توان آن را کمینه کرد:
 	\[
 	\frac{\partial J}{\partial \mu_j} = 0 \implies  \sum_{x^{(i)} \in C_j} -2 \left( x^{(i)} - \mu_j \right) = 0
 	\]
 	\item این به این معناست که هر $\mu_j$ باید به‌عنوان میانگین خوشه $C_j$ به‌روزرسانی شود:
 	\[
 	\mu_j = \frac{\sum_{x^{(i)} \in C_j} x^{(i)}}{|C_j|}
 	\]
 \end{itemize}
\begin{itemize}[label={\color{black}$\bullet$}]
	\item برای هر خوشه، میانگین نقاط آن خوشه مقدار مجموع فاصله‌های مربعی را کمینه می‌کند.
	
	\item برای خوشه‌ی $C_j$، اگر $\mu'_j$ مرکز قبلی باشد، داریم:
	\[
	\sum_{x^{(i)} \in C_j} \|x^{(i)} - \mu'_j\|^2 
	\;\ge\; 
	\sum_{x^{(i)} \in C_j} \|x^{(i)} - \mu_j\|^2
	\]
	یعنی انتخاب میانگین جدید هرگز مقدار خطا را افزایش نمی‌دهد.
	
	\item در نتیجه، $J_{\text{\lr{new}}} \le J_{\text{\lr{old}}}$ خواهد بود.
	
	\item از آنجایی که تابع هزینه $J$ غیرمنفی است و تعداد تقسیم‌بندی‌های ممکن نیز محدود می‌باشد، دنباله مقادیر $J$ نمی‌تواند تا بی‌نهایت کاهش یابد.
	
	\item بنابراین الگوریتم \lr{K-Means} در نهایت همگرا می‌شود.
	
	\item ویژگی‌های همگرایی الگوریتم \lr{K-Means} نخستین‌بار توسط مک‌کوئین \lr{(MacQueen)} در سال 1967 بررسی شد.
\end{itemize}
 \lr{cost}
 همان طوری که در تصویر مشاهده می شود در نهایت کمتر و کمتر می شود. و به یک نقطه صفر می رسد که بهترین جواب را پیدا خواهد کرد.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{kmeans_iter_6.png}
	\caption{نمودار تابع هزینه در \lr{k-means}}
	\label{fig:my_label}
\end{figure}
\end{document}